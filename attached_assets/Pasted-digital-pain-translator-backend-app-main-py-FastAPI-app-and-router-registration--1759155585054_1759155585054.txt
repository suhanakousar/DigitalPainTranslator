digital-pain-translator/
├─ backend/
│ ├─ app/
│ │ ├─ main.py # FastAPI app and router registration
│ │ ├─ routers/
│ │ │ ├─ infer.py # REST & WebSocket inference endpoints
│ │ │ ├─ records.py # store/get inference records
│ │ │ ├─ admin.py # health, reload model endpoints
│ │ ├─ models/
│ │ │ ├─ sequence_model.py # PyTorch model class (LSTM or 1D-CNN)
│ │ │ ├─ trainer.py # training loop functions (expects external data)
│ │ ├─ inference/
│ │ │ ├─ predictor.py # model loading, preprocessing, inference & attribution
│ │ │ ├─ feature_extractor.py # deterministic formulas ported to Python (no example values)
│ │ ├─ schemas.py # pydantic request/response models (no example values)
│ │ ├─ utils.py # helpers (distance, normalization, variance, UUID)
│ │ ├─ config.py # paths, constants, hyperparams (no sample data)
│ ├─ Dockerfile
│ ├─ requirements.txt
│ ├─ train.py # CLI script to run training (expects user-supplied data)
│ ├─ eval.py # CLI script for evaluation & model export
│ ├─ demo_data/ # EMPTY placeholder directory, DO NOT add example files
│ │ ├─ README.md # instructions on how to format and add data (no examples)
│ ├─ tests/
│ │ ├─ test_feature_extractor.py # programmatically generated test inputs
│ │ ├─ test_predictor.py
│ │ ├─ test_api_infer.py
│ ├─ docker-compose.yml
├─ frontend/ (update)
│ ├─ src/
│ │ ├─ services/
│ │ │ ├─ apiClient.js # REST client for server-assisted mode
│ │ │ ├─ wsClient.js # WebSocket client integration
│ │ ├─ components/
│ │ │ ├─ ServerToggle.jsx # toggles local/server-assisted mode with explicit consent
│ │ │ ├─ (existing components updated to call server when toggled)
│ ├─ dockerfile (optional)
├─ demo_video_script.md # text-only script instructions (no sample payloads)
├─ README.md # global README with instructions (no example data)
└─ LICENSE


API specification — contracts (no example payloads)
--------------------------------------------------
Define the JSON schemas for requests and responses including required fields and types, but do NOT include concrete example values. Ensure the schemas are validated by Pydantic and frontend validation logic.

- **POST /api/infer**
  - Accepts either `landmarks` or `features` and caregiverInputs. Required fields must be enforced; optional fields allowed. Return JSON with `session_id`, `score`, `confidence`, `explanation` (list of signal/contribution pairs), `recommendedActions`, `model_version`, and `processing_ms`.

- **WebSocket /ws/infer**
  - Accepts the same JSON messages as POST and returns equivalent response messages.

- **GET /api/records** and **POST /api/records**
  - Standard list and create semantics. Persist records in a local JSON file or database depending on config. Do not pre-populate with any records.

Model & training guidance
-------------------------
- Implement two inference backends:
  1. **Baseline deterministic** (same explainable weighted linear model used in frontend) as fallback.
  2. **PyTorch sequence model** (LSTM or 1D-CNN) for improved accuracy. Trainer must accept user-supplied datasets and must not include sample datasets.
- Provide code to export trained model to ONNX or TorchScript for production use (no example export files included).
- Include a training CLI (`train.py`) with arguments for data directory, batch size, epochs, checkpoint path, and evaluation options. The script should clearly describe expected data format in README (no sample files).

Explainability
--------------
- Baseline: return explicit per-feature contributions as `weight * normalized_value`.
- ML model: implement a runtime gradient-based attribution method (Integrated Gradients fallback or simple gradient * input) that returns per-feature attribution aggregated across the input sequence. Do not include SHAP example outputs or datasets.

Testing (no example data)
-------------------------
- Create unit tests that generate synthetic inputs programmatically (random or deterministic values created inside the tests) to validate:
  - feature computation functions produce values within expected numeric ranges,
  - predictor returns correct response schema,
  - REST endpoint responds with correct HTTP codes and JSON structure.
- Tests must not load or use any file-based example/demo data.

Frontend integration
--------------------
- Add a `ServerToggle.jsx` that:
  - Shows a consent modal when enabling `Server-assisted` mode.
  - Records consent state in localStorage.
- Add `apiClient.js` and `wsClient.js` to send validated payloads and handle backend responses. Client must handle:
  - successful inference response display,
  - errors and fallbacks to Local-only mode,
  - display of `model_version` and `processing_ms` if supplied.
- Ensure that the frontend does not include any example/demo payloads or demo data in the build.

Deployment & Docker
-------------------
- Provide a Dockerfile for backend and `docker-compose.yml` to run frontend + backend locally for development. Do NOT place credentials or sample data in images. Document how to supply secrets and real data at runtime.

Documentation
-------------
- README must include:
  - Setup and run instructions for dev (backend & frontend),
  - Training guide describing expected data format (no concrete samples),
  - API specification with field types and validation rules (no sample JSON),
  - Privacy & consent guidance and explicit note that the app is a research prototype and not a medical device,
  - Commands for Docker-based local deployment and for model export.
- demo_data/ must contain ONLY an instruction README (no sample files). Explain how contributors should add their own data.

Security & privacy
------------------
- Emphasize opt-in server-assisted mode; record consent.
- Recommend TLS for production and document local dev alternatives.
- Provide guidance on minimizing stored sensitive data and how to encrypt or purge records.

Acceptance criteria checklist (for the assistant)
------------------------------------------------
- [ ] FastAPI backend with REST `/api/infer` that validates input and returns expected response schema.
- [ ] WebSocket `/ws/infer` supporting one-shot inference messages.
- [ ] Predictor that can load either baseline or PyTorch model and falls back to baseline if no model is present.
- [ ] Feature extraction implemented in Python (same formulas as the frontend).
- [ ] Training pipeline (trainer + train.py) that accepts user-supplied datasets (no sample data included).
- [ ] Explainability support: baseline contributions + gradient-based attribution for ML model.
- [ ] Dockerfile + docker-compose for local development (no embedded data).
- [ ] Frontend integration: ServerToggle, apiClient, wsClient; opt-in consent logic.
- [ ] Unit tests that programmatically generate inputs (no example files).
- [ ] README with instructions describing data format but containing no sample payloads or demo data.
- [ ] No example/demo data, sample JSON, or prefilled example values in any repository files.

Developer notes
---------------
- Produce clear, well-commented code and docstrings.
- If optional heavy dependencies (e.g., SHAP) are included, make them optional and documented; do not include example outputs.
- When a file would normally contain sample/demo data, create an empty placeholder and a README explaining how to populate it.

Now generate the full backend code and all integration changes described above, strictly following the "NO EXAMPLES 